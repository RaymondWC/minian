{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Specify Directory and File Information\n",
    "\n",
    "`minian_path` is the directory containing minian, `dpath` is the directory containing the videos to be cross-registered and their corresponding minian output data (each pair of videos+output should be in a unique folder), `f_pattern` is a regular expression identifying the naming pattern of minian output folders with a regex expression (e.g. `'minian$'`, or `r'minian\\.[0-9]+$'` if data is batch processed and has a timestamp), and `id_dims` should be a list containing metadata identifiers used when analyzing the individual sessions (e.g. `['session','animal']`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "minian_path = \".\"\n",
    "dpath = \"./demo_movies\"\n",
    "f_pattern = r'minian\\.[0-9]+$' \n",
    "id_dims = ['animal','session']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Paramaters\n",
    "`param_t_dist` defines the maximal distance between cell centroids (in pixel units) on different sessions to consider them as the same cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_t_dist = 5\n",
    "output_size = 90"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import os\n",
    "import sys\n",
    "import warnings\n",
    "sys.path.append(minian_path)\n",
    "import itertools as itt\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "import holoviews as hv\n",
    "import pandas as pd\n",
    "from holoviews.operation.datashader import datashade, regrid\n",
    "from minian.cross_registration import (calculate_centroids, calculate_centroid_distance, calculate_mapping,\n",
    "                                       group_by_session, resolve_mapping, fill_mapping)\n",
    "from minian.motion_correction import estimate_shifts, apply_shifts\n",
    "from minian.utilities import open_minian, open_minian_mf\n",
    "from minian.visualization import AlignViewer\n",
    "hv.notebook_extension('bokeh', width=100)\n",
    "pbar = ProgressBar(minimum=2)\n",
    "pbar.register()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Allign Videos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## open datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "minian_ds = open_minian_mf(\n",
    "    dpath, id_dims, pattern=f_pattern, backend='zarr')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## estimate shifts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "temps = minian_ds['Y'].max('frame').compute().rename('temps')\n",
    "shifts = estimate_shifts(temps, dim='session').compute()\n",
    "temps_sh = apply_shifts(temps, shifts).compute().rename('temps_shifted')\n",
    "shiftds = xr.merge([temps, shifts, temps_sh])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## visualize alignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hv.output(size=output_size)\n",
    "opts_im = {\n",
    "    'aspect': shiftds.sizes['width'] / shiftds.sizes['height'],\n",
    "    'frame_width': 500, 'cmap': 'viridis'}\n",
    "hv_temps = (hv.Dataset(temps).to(hv.Image, kdims=['width', 'height'])\n",
    "            .opts(**opts_im).layout('session').cols(1))\n",
    "hv_temps_sh = (hv.Dataset(temps_sh).to(hv.Image, kdims=['width', 'height'])\n",
    "            .opts(**opts_im).layout('session').cols(1))\n",
    "display(hv_temps + hv_temps_sh)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## visualize overlap of field of view across all sessions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hv.output(size=output_size)\n",
    "opts_im = {\n",
    "    'aspect': shiftds.sizes['width'] / shiftds.sizes['height'],\n",
    "    'frame_width': 500, 'cmap': 'viridis'}\n",
    "window = shiftds['temps_shifted'].isnull().sum('session')\n",
    "window, temps_sh = xr.broadcast(window, shiftds['temps_shifted'])\n",
    "hv_wnd = hv.Dataset(window, kdims=list(window.dims)).to(hv.Image, ['width', 'height'])\n",
    "hv_temps = hv.Dataset(temps_sh, kdims=list(temps_sh.dims)).to(hv.Image, ['width', 'height'])\n",
    "hv_wnd.opts(**opts_im).relabel(\"Window\") + hv_temps.opts(**opts_im).relabel(\"Shifted Templates\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## apply shifts and set window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A_shifted = apply_shifts(minian_ds['A'].chunk(dict(height=-1, width=-1)), shiftds['shifts'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_window(wnd):\n",
    "    return wnd == wnd.min()\n",
    "window = xr.apply_ufunc(\n",
    "    set_window,\n",
    "    window,\n",
    "    input_core_dims=[['height', 'width']],\n",
    "    output_core_dims=[['height', 'width']],\n",
    "    vectorize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate Centroid Distance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## calculate centroids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "cents = calculate_centroids(A_shifted, window)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## calculate centroid distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "dist = calculate_centroid_distance(cents, index_dim=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Overlap Across Sessions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### threshold overlap based upon centroid distance and generate overlap mappings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dist_ft = dist[dist['variable', 'distance'] < param_t_dist]\n",
    "dist_ft = group_by_session(dist_ft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "mappings = calculate_mapping(dist_ft)\n",
    "mappings_meta = resolve_mapping(mappings)\n",
    "mappings_meta_fill = fill_mapping(mappings_meta, cents)\n",
    "mappings_meta_fill.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### save overlap mappings to pkl and csv files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mappings_meta_fill.to_pickle(os.path.join(dpath, \"mappings.pkl\"))\n",
    "mappings_meta_fill.to_csv(os.path.join(dpath, \"mappings.csv\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# View Overlap Across Any 2 Sessions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### define session names to be compared in list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = ['Day1', 'Day2']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### view overlapping/non-overlapping cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def subset_by_session(sessions, mappings):\n",
    "    mappings_ma = mappings[mappings['session'][sessions].notnull().all(axis='columns')]\n",
    "    mappings_non = mappings[\n",
    "        mappings['group', 'group'].isnull()\n",
    "        & mappings['session'][sess].notnull().any(axis='columns')]\n",
    "    return mappings_ma, mappings_non"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mappings_match, mappings_nonmatch = subset_by_session(sess, mappings_meta_fill)\n",
    "opts_im = {\n",
    "    'frame_width': 500,\n",
    "    'aspect': A_shifted.sizes['width'] / A_shifted.sizes['height'],\n",
    "    'cmap': 'viridis'}\n",
    "A_dict = dict()\n",
    "for ss in sess:\n",
    "    uid_ma = mappings_match[('session', ss)].values\n",
    "    uid_nm = mappings_nonmatch[('session', ss)].dropna().values\n",
    "    cent_ma = cents[(cents['session'] == ss) & (cents['unit_id'].isin(uid_ma))]\n",
    "    cent_nm = cents[(cents['session'] == ss) & (cents['unit_id'].isin(uid_nm))]\n",
    "    hv_A_ma = hv.Image(\n",
    "        A_shifted.sel(session=ss, unit_id=uid_ma).sum('unit_id').compute(),\n",
    "        ['width', 'height']).opts(**opts_im)\n",
    "    hv_A_nm = hv.Image(\n",
    "        A_shifted.sel(session=ss, unit_id=uid_nm).sum('unit_id').compute(),\n",
    "        ['width', 'height']).opts(**opts_im)\n",
    "    A_dict[(ss, 'matching')] = hv_A_ma\n",
    "    A_dict[(ss, 'non-matching')] = hv_A_nm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hv.NdLayout(A_dict, kdims=['session', 'ma']).cols(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mappings_match, mappings_nonmatch = subset_by_session(sess, mappings_meta_fill)\n",
    "A_dict = dict()\n",
    "cent_dict = dict()\n",
    "for cur_ss in sess:\n",
    "    cur_uid_ma = mappings_match[[('meta', d) for d in group_dim] + [('session', cur_ss)]]\n",
    "    cur_uid_nm = mappings_nonmatch[[('meta', d) for d in group_dim] + [('session', cur_ss)]].dropna()\n",
    "    cur_uid_ma.columns = cur_uid_ma.columns.droplevel()\n",
    "    cur_uid_nm.columns = cur_uid_nm.columns.droplevel()\n",
    "    cur_uid_ma = cur_uid_ma.rename(columns={cur_ss:'unit_id'})\n",
    "    cur_uid_nm = cur_uid_nm.rename(columns={cur_ss:'unit_id'})\n",
    "    cur_uid_ma['session'] = cur_ss\n",
    "    cur_uid_nm['session'] = cur_ss\n",
    "    cur_cents_ma = cur_uid_ma.merge(cents)\n",
    "    cur_cents_nm = cur_uid_nm.merge(cents)\n",
    "    A_ma_dict = dict()\n",
    "    A_nm_dict = dict()\n",
    "    for igrp, grp_ma in cur_uid_ma.groupby(group_dim + ['session']):\n",
    "        cur_keys = {d: k for d, k in zip(group_dim + ['session'], igrp)}\n",
    "        A_sub = A_shifted.sel(**cur_keys)\n",
    "        A_ma = A_sub.sel(unit_id=grp_ma['unit_id'].values)\n",
    "        grp_nm = cur_uid_nm.query(\" and \".join([\"==\".join((d, \"'{}'\".format(k))) for d, k in cur_keys.items()]))\n",
    "        A_nm = A_sub.sel(unit_id=grp_nm['unit_id'].values)\n",
    "        A_ma_dict[igrp] = hv.Image(A_ma.sum('unit_id').compute(), kdims=['width', 'height'])\n",
    "        A_nm_dict[igrp] = hv.Image(A_nm.sum('unit_id').compute(), kdims=['width', 'height'])\n",
    "    hv_A_ma = hv.HoloMap(A_ma_dict, kdims=group_dim + ['session'])\n",
    "    hv_A_nm = hv.HoloMap(A_nm_dict, kdims=group_dim + ['session'])\n",
    "    hv_cent_ma = hv.Dataset(cur_cents_ma).to(hv.Points, kdims=['width', 'height'])\n",
    "    hv_cent_nm = hv.Dataset(cur_cents_nm).to(hv.Points, kdims=['width', 'height'])\n",
    "    hv_A = hv.HoloMap(dict(match=hv_A_ma, nonmatch=hv_A_nm), kdims=['matching']).collate()\n",
    "    hv_cent = hv.HoloMap(dict(match=hv_cent_ma, nonmatch=hv_cent_nm), kdims=['matching']).collate()\n",
    "    A_dict[cur_ss] = hv_A\n",
    "    cent_dict[cur_ss] = hv_cent\n",
    "hv_A = hv.HoloMap(A_dict, kdims=['session']).collate()\n",
    "hv_cent = hv.HoloMap(cent_dict, kdims=['session']).collate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%output size=60\n",
    "from holoviews.operation.datashader import regrid\n",
    "(regrid(hv_A).opts(plot=dict(width=752, height=480), style=dict(cmap='Viridis'))).layout(['animal', 'matching']).cols(2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
